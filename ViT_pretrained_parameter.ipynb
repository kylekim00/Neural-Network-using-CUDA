{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "model = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
    "\n",
    "config = resolve_data_config({}, model=model)\n",
    "transform = create_transform(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dc = model.named_children()\n",
    "# dc = list(dc)\n",
    "# x = torch.arange(4*3*224*224, dtype=torch.float32).reshape(4, 3, 224, 224)\n",
    "# x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## block WEIGHT binaryfile 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in range(12):\n",
    "    block = dict(dict(dict(model.named_children())['blocks'].named_children())[str(layer)].named_children())\n",
    "    ls = [block['norm1'],list(block['attn'].children())[0], list(block['attn'].children())[4],block['norm2'],list(block['mlp'].children())[0], list(block['mlp'].children())[4]]\n",
    "\n",
    "    weight_ls = list()\n",
    "    for i in range(len(ls)):\n",
    "        weight_ls.append(ls[i].weight.clone().detach().numpy().T)\n",
    "        weight_ls.append(ls[i].bias.clone().detach().numpy())\n",
    "\n",
    "    blk_weight = np.array(weight_ls[0].flatten())\n",
    "\n",
    "    for i in range(1, len(weight_ls)):\n",
    "        blk_weight = np.concatenate((blk_weight, weight_ls[i].flatten()))\n",
    "    blk_weight.tofile('./pre_weights/'+str(layer)+'_newblock'+'.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QKV WEIGHT BINFILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 0\n",
    "dd = dict(list(list(model.named_children())[4][1].children())[layer].named_children())\n",
    "blk = dict(dd['attn'].named_children())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dummy input check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(10)\n",
    "dummy_input = torch.randn((4, 196, 768))\n",
    "qkv_w = dict(dd['attn'].named_children())['qkv'].weight.clone().detach().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy_input.numpy().tofile('./pre_weights/dummy_input_4_196_768.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 196, 768])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768, 2304])\n",
      "torch.Size([2304])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([768, 3072])\n",
      "torch.Size([3072])\n",
      "torch.Size([3072, 768])\n",
      "torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "blocks = list()\n",
    "for layer in range(12):\n",
    "    block = dict(dict(dict(model.named_children())['blocks'].named_children())[str(layer)].named_children())\n",
    "    ls = [list(block['attn'].children())[0], list(block['attn'].children())[4],list(block['mlp'].children())[0], list(block['mlp'].children())[4]]\n",
    "\n",
    "    weight_ls = list()\n",
    "    for i in range(len(ls)):\n",
    "        weight_ls.append(ls[i].weight.clone().detach().T)\n",
    "        weight_ls.append(ls[i].bias.clone().detach())\n",
    "    blocks.append(weight_ls)\n",
    "\n",
    "    \n",
    "\n",
    "for i in blocks[0]:\n",
    "    print(i.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLASH ATTENTION VALUE CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2055, -0.1736,  0.4550,  0.2223, -0.0058, -0.1951,  0.1081, -0.0950],\n",
       "        [-0.2403, -0.1827,  0.3924,  0.2354, -0.0299, -0.1278,  0.1057, -0.0935],\n",
       "        [-0.2598, -0.1673,  0.4965,  0.2337, -0.0930, -0.1645,  0.0652, -0.0784],\n",
       "        [-0.2632, -0.1369,  0.4431,  0.2356,  0.0452, -0.1379,  0.0822, -0.0350],\n",
       "        [-0.2474, -0.1771,  0.3949,  0.1860,  0.0159, -0.1896,  0.0057, -0.0729],\n",
       "        [-0.2212, -0.1546,  0.4233,  0.1712, -0.0062, -0.1302,  0.0796, -0.0667],\n",
       "        [-0.2667, -0.1787,  0.4048,  0.2312,  0.0124, -0.1626,  0.1034, -0.1029],\n",
       "        [-0.2447, -0.1572,  0.4262,  0.2408,  0.0147, -0.1515,  0.0910, -0.0736]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block = dict(dict(dict(model.named_children())['blocks'].named_children())[str(layer)].named_children())\n",
    "# Fetch correct qkv weights and biases from the block\n",
    "qkv_layer = dict(block['attn'].named_children())['qkv']\n",
    "qkv_weights = qkv_layer.weight  # Shape: (out_features, in_features)\n",
    "qkv_bias = qkv_layer.bias\n",
    "\n",
    "# Transpose qkv_weights to shape (in_features, out_features) for matrix multiplication\n",
    "qkv_weights = qkv_weights.T  # Now shape: (in_features, out_features)\n",
    "\n",
    "# Apply the QKV linear projection with the correct transposed weights and biases\n",
    "dQKV = torch.add(torch.matmul(dummy_input, qkv_weights), qkv_bias)\n",
    "\n",
    "# Reshape and permute to get the correct multi-head attention format\n",
    "dQKV = dQKV.view(4, 196, 12, 3, 64)  # (batch, seq_len, num_heads, qkv, head_dim)\n",
    "dQKV = torch.einsum('b p h k d -> b h k p d', dQKV)  # Permute dimensions\n",
    "\n",
    "# Calculate attention manually for each head\n",
    "Os = list()\n",
    "for i in range(12):\n",
    "    Q = dQKV[0][i][0]  # Query for head i\n",
    "    K = dQKV[0][i][1]  # Key for head i\n",
    "    V = dQKV[0][i][2]  # Value for head i\n",
    "    \n",
    "    # Apply scaled dot-product attention with numerical stability\n",
    "    attn_weights = torch.matmul(Q, K.T) / (Q.size(-1) ** 0.5)  # Scale by sqrt(d_k)\n",
    "    attn_weights = attn_weights - torch.max(attn_weights, dim=-1, keepdim=True)[0]  # Numerical stability\n",
    "    attn_weights = torch.nn.functional.softmax(attn_weights, dim=-1)\n",
    "    \n",
    "    O = torch.matmul(attn_weights, V)  # Multiply attention weights by V\n",
    "    Os.append(O)\n",
    "\n",
    "# Concatenate outputs from all heads and apply the projection layer\n",
    "concat_Os = torch.cat(Os, dim=1)  # Concatenate along the feature dimension (head outputs)\n",
    "proj_output = dict(block['attn'].named_children())['proj'](concat_Os)[:8, :8]  # Apply projection layer\n",
    "proj_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.1279)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 12, 196, 64])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk1 = blocks[0]\n",
    "torch.manual_seed(10)\n",
    "blk1[0] = blk1[0].to(torch.float32)\n",
    "blk1[1] = blk1[1].to(torch.float32)\n",
    "\n",
    "dummy_input = torch.randn((4, 196, 768), dtype=torch.float32)\n",
    "print(torch.matmul(dummy_input,blk1[0])[0][0][1])\n",
    "dQKV = torch.add(torch.matmul(dummy_input,blk1[0]), blk1[1])\n",
    "dQKV = dQKV.view(4, 196, 3, 12, 64)\n",
    "dQKV = torch.einsum('b p k h d -> k b h p d',dQKV)\n",
    "dQKV.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qs, Ks, Vs = dQKV.unbind(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 : batch\n",
    "12 : Multi head\n",
    "3 : QKV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = Qs[0][0]# batch head\n",
    "K = Ks[0][0]\n",
    "V = Vs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([196, 64])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.matmul(torch.nn.functional.softmax(torch.matmul(Q, K.T), dim=1),V)[188:196,8:16]#일반 ATTN\n",
    "torch.matmul(torch.nn.functional.softmax(torch.matmul(Q, K.T), dim=1),V).shape#일반 ATTN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0201,  0.1241,  0.2855, -0.2697, -0.2250,  0.6140, -0.0903, -0.4683],\n",
       "        [ 0.5427, -0.0843,  0.0165, -0.2499, -0.4020,  0.5875, -0.0717, -0.6233],\n",
       "        [ 0.0990, -0.1040,  0.1056, -0.0610, -0.2217,  0.2057, -0.0635, -0.3588],\n",
       "        [ 0.3024, -0.0653, -0.0542, -0.2307, -0.2722,  0.1737, -0.0037, -0.5988],\n",
       "        [ 0.0938,  0.0728,  0.3319, -0.3459, -0.2872,  0.4283,  0.2563, -0.3149],\n",
       "        [ 0.1920, -0.0805,  0.0075, -0.2601, -0.2883,  0.2606, -0.1216, -0.2211],\n",
       "        [ 0.2577, -0.0885,  0.0766, -0.2594, -0.2453,  0.4059,  0.0835, -0.2692],\n",
       "        [ 0.3502, -0.3796,  0.2173, -0.5175, -0.1211,  0.9736,  0.1606, -0.3987]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Os = list()\n",
    "for i in range(12):\n",
    "    Q = Qs[0][i]# batch head\n",
    "    K = Ks[0][i]\n",
    "    V = Vs[0][i]\n",
    "    O = torch.matmul(torch.nn.functional.softmax(torch.matmul(Q, K.T)/8, dim=1),V)\n",
    "    Os.append(O)\n",
    "torch.concat(Os, dim=1)[:8,:8]\n",
    "dict(block['attn'].named_children())['proj'](torch.concat(Os, dim=1))[:8,:8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1160,  0.0130,  0.1180,  0.0090, -0.0920, -0.2190,  0.1030,  0.2480],\n",
      "        [ 0.2220, -0.0080, -0.1670,  0.0520, -0.0000, -0.0100, -0.0760,  0.3100],\n",
      "        [ 0.1020, -0.0650,  0.1430,  0.0320, -0.0640, -0.2800,  0.0630,  0.3230],\n",
      "        [ 0.0510,  0.0880, -0.0770,  0.2210,  0.0650, -0.2940,  0.0600,  0.1930],\n",
      "        [ 0.0970, -0.0080,  0.1480, -0.0320, -0.0160, -0.2480,  0.1040,  0.0700],\n",
      "        [ 0.1160, -0.1060,  0.1930,  0.0130,  0.0290, -0.1590,  0.1320,  0.1870],\n",
      "        [ 0.0990, -0.0990,  0.0100, -0.0660, -0.0790, -0.1010,  0.1420, -0.0100],\n",
      "        [ 0.1710, -0.0330,  0.1460, -0.1300, -0.1790, -0.2540,  0.1940,  0.0700]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'norm1': LayerNorm((768,), eps=1e-06, elementwise_affine=True),\n",
       " 'attn': Attention(\n",
       "   (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "   (q_norm): Identity()\n",
       "   (k_norm): Identity()\n",
       "   (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "   (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'ls1': Identity(),\n",
       " 'drop_path1': Identity(),\n",
       " 'norm2': LayerNorm((768,), eps=1e-06, elementwise_affine=True),\n",
       " 'mlp': Mlp(\n",
       "   (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (act): GELU(approximate='none')\n",
       "   (drop1): Dropout(p=0.0, inplace=False)\n",
       "   (norm): Identity()\n",
       "   (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (drop2): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'ls2': Identity(),\n",
       " 'drop_path2': Identity()}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = 0\n",
    "block = dict(dict(dict(model.named_children())['blocks'].named_children())[str(layer)].named_children())\n",
    "# list(block['attn'].children())[0]\n",
    "ls = [list(block['attn'].children())[0], list(block['attn'].children())[4],list(block['mlp'].children())[0], list(block['mlp'].children())[4]]\n",
    "ls[0]\n",
    "block['attn']\n",
    "print(torch.round((block['attn'](dummy_input))[2,188:,760:]*1000)/1000)\n",
    "# torch.round(dict(dict(model.named_children())['blocks'].named_children())[str(0)](dummy_input)[0,:8,:8]*100)/100\n",
    "block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attention(\n",
       "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "  (q_norm): Identity()\n",
       "  (k_norm): Identity()\n",
       "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block['attn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kkh38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
