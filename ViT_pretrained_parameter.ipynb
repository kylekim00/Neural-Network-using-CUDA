{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "model = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
    "\n",
    "config = resolve_data_config({}, model=model)\n",
    "transform = create_transform(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dc = model.named_children()\n",
    "# dc = list(dc)\n",
    "# x = torch.arange(4*3*224*224, dtype=torch.float32).reshape(4, 3, 224, 224)\n",
    "# x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## block WEIGHT binaryfile 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in range(12):\n",
    "    block = dict(dict(dict(model.named_children())['blocks'].named_children())[str(layer)].named_children())\n",
    "    ls = [block['norm1'],list(block['attn'].children())[0], list(block['attn'].children())[4],block['norm2'],list(block['mlp'].children())[0], list(block['mlp'].children())[4]]\n",
    "\n",
    "    weight_ls = list()\n",
    "    for i in range(len(ls)):\n",
    "        weight_ls.append(ls[i].weight.clone().detach().numpy().T)\n",
    "        weight_ls.append(ls[i].bias.clone().detach().numpy())\n",
    "\n",
    "    blk_weight = np.array(weight_ls[0].flatten())\n",
    "\n",
    "    for i in range(1, len(weight_ls)):\n",
    "        blk_weight = np.concatenate((blk_weight, weight_ls[i].flatten()))\n",
    "    blk_weight.tofile('./pre_weights/'+str(layer)+'_newblock'+'.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QKV WEIGHT BINFILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 0\n",
    "dd = dict(list(list(model.named_children())[4][1].children())[layer].named_children())\n",
    "blk = dict(dd['attn'].named_children())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dummy input check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(10)\n",
    "dummy_input = torch.randn((4, 196, 768))\n",
    "qkv_w = dict(dd['attn'].named_children())['qkv'].weight.clone().detach().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy_input.numpy().tofile('./pre_weights/dummy_input_4_196_768.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 196, 768])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768, 2304])\n",
      "torch.Size([2304])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([768, 3072])\n",
      "torch.Size([3072])\n",
      "torch.Size([3072, 768])\n",
      "torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "blocks = list()\n",
    "for layer in range(12):\n",
    "    block = dict(dict(dict(model.named_children())['blocks'].named_children())[str(layer)].named_children())\n",
    "    ls = [list(block['attn'].children())[0], list(block['attn'].children())[4],list(block['mlp'].children())[0], list(block['mlp'].children())[4]]\n",
    "\n",
    "    weight_ls = list()\n",
    "    for i in range(len(ls)):\n",
    "        weight_ls.append(ls[i].weight.clone().detach().T)\n",
    "        weight_ls.append(ls[i].bias.clone().detach())\n",
    "    blocks.append(weight_ls)\n",
    "\n",
    "    \n",
    "\n",
    "for i in blocks[0]:\n",
    "    print(i.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLASH ATTENTION VALUE CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2055, -0.1736,  0.4550,  0.2223, -0.0058, -0.1951,  0.1081, -0.0950],\n",
       "        [-0.2403, -0.1827,  0.3924,  0.2354, -0.0299, -0.1278,  0.1057, -0.0935],\n",
       "        [-0.2598, -0.1673,  0.4965,  0.2337, -0.0930, -0.1645,  0.0652, -0.0784],\n",
       "        [-0.2632, -0.1369,  0.4431,  0.2356,  0.0452, -0.1379,  0.0822, -0.0350],\n",
       "        [-0.2474, -0.1771,  0.3949,  0.1860,  0.0159, -0.1896,  0.0057, -0.0729],\n",
       "        [-0.2212, -0.1546,  0.4233,  0.1712, -0.0062, -0.1302,  0.0796, -0.0667],\n",
       "        [-0.2667, -0.1787,  0.4048,  0.2312,  0.0124, -0.1626,  0.1034, -0.1029],\n",
       "        [-0.2447, -0.1572,  0.4262,  0.2408,  0.0147, -0.1515,  0.0910, -0.0736]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block = dict(dict(dict(model.named_children())['blocks'].named_children())[str(layer)].named_children())\n",
    "# Fetch correct qkv weights and biases from the block\n",
    "qkv_layer = dict(block['attn'].named_children())['qkv']\n",
    "qkv_weights = qkv_layer.weight  # Shape: (out_features, in_features)\n",
    "qkv_bias = qkv_layer.bias\n",
    "\n",
    "# Transpose qkv_weights to shape (in_features, out_features) for matrix multiplication\n",
    "qkv_weights = qkv_weights.T  # Now shape: (in_features, out_features)\n",
    "\n",
    "# Apply the QKV linear projection with the correct transposed weights and biases\n",
    "dQKV = torch.add(torch.matmul(dummy_input, qkv_weights), qkv_bias)\n",
    "\n",
    "# Reshape and permute to get the correct multi-head attention format\n",
    "dQKV = dQKV.view(4, 196, 12, 3, 64)  # (batch, seq_len, num_heads, qkv, head_dim)\n",
    "dQKV = torch.einsum('b p h k d -> b h k p d', dQKV)  # Permute dimensions\n",
    "\n",
    "# Calculate attention manually for each head\n",
    "Os = list()\n",
    "for i in range(12):\n",
    "    Q = dQKV[0][i][0]  # Query for head i\n",
    "    K = dQKV[0][i][1]  # Key for head i\n",
    "    V = dQKV[0][i][2]  # Value for head i\n",
    "    \n",
    "    # Apply scaled dot-product attention with numerical stability\n",
    "    attn_weights = torch.matmul(Q, K.T) / (Q.size(-1) ** 0.5)  # Scale by sqrt(d_k)\n",
    "    attn_weights = attn_weights - torch.max(attn_weights, dim=-1, keepdim=True)[0]  # Numerical stability\n",
    "    attn_weights = torch.nn.functional.softmax(attn_weights, dim=-1)\n",
    "    \n",
    "    O = torch.matmul(attn_weights, V)  # Multiply attention weights by V\n",
    "    Os.append(O)\n",
    "\n",
    "# Concatenate outputs from all heads and apply the projection layer\n",
    "concat_Os = torch.cat(Os, dim=1)  # Concatenate along the feature dimension (head outputs)\n",
    "proj_output = dict(block['attn'].named_children())['proj'](concat_Os)[:8, :8]  # Apply projection layer\n",
    "proj_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.1279)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 12, 196, 64])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk1 = blocks[0]\n",
    "torch.manual_seed(10)\n",
    "blk1[0] = blk1[0].to(torch.float32)\n",
    "blk1[1] = blk1[1].to(torch.float32)\n",
    "\n",
    "dummy_input = torch.randn((4, 196, 768), dtype=torch.float32)\n",
    "print(torch.matmul(dummy_input,blk1[0])[0][0][1])\n",
    "dQKV = torch.add(torch.matmul(dummy_input,blk1[0]), blk1[1])\n",
    "dQKV = dQKV.view(4, 196, 3, 12, 64)\n",
    "dQKV = torch.einsum('b p k h d -> k b h p d',dQKV)\n",
    "dQKV.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qs, Ks, Vs = dQKV.unbind(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 : batch\n",
    "12 : Multi head\n",
    "3 : QKV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = Qs[0][0]# batch head\n",
    "K = Ks[0][0]\n",
    "V = Vs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([196, 64])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.matmul(torch.nn.functional.softmax(torch.matmul(Q, K.T), dim=1),V)[188:196,8:16]#일반 ATTN\n",
    "torch.matmul(torch.nn.functional.softmax(torch.matmul(Q, K.T), dim=1),V).shape#일반 ATTN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4365, -0.0053, -2.0785, -0.1310,  0.3362, -0.7637, -0.1959, -0.0355],\n",
       "        [ 0.1909, -0.0482, -0.0667, -0.1483,  0.0187, -0.6523, -0.2404,  0.1926],\n",
       "        [-0.4567,  0.0283,  0.0388, -0.0864,  0.1838, -0.6500, -0.1512,  0.2088],\n",
       "        [ 0.0561,  0.0061,  0.0934, -0.1666,  0.1272, -0.5512, -0.3549,  0.0698],\n",
       "        [-0.0255,  0.0720, -0.7790, -0.0651,  0.1271, -0.1607, -0.1948,  0.0879],\n",
       "        [-0.3870,  0.0909,  0.0525, -0.0342,  0.0777, -0.5152, -0.1509,  0.0721],\n",
       "        [-0.1256,  0.1418,  0.0562, -0.1245, -0.0947, -0.1670, -0.3574,  0.1665],\n",
       "        [ 0.1702,  0.2194, -0.7297, -0.1137, -0.2793,  0.2847, -0.5775,  0.2026]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Os = list()\n",
    "for i in range(12):\n",
    "    Q = Qs[0][i]# batch head\n",
    "    K = Ks[0][i]\n",
    "    V = Vs[0][i]\n",
    "    O = torch.matmul(torch.nn.functional.softmax(torch.matmul(Q, K.T)/8, dim=1),V)\n",
    "    Os.append(O)\n",
    "torch.concat(Os, dim=1)[:8,:8]\n",
    "dict(block['attn'].named_children())['proj'](torch.concat(Os, dim=1))[:8,:8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4365, -0.0053, -2.0785, -0.1310,  0.3362, -0.7637, -0.1959, -0.0355],\n",
      "        [ 0.1909, -0.0482, -0.0667, -0.1483,  0.0187, -0.6523, -0.2404,  0.1926],\n",
      "        [-0.4567,  0.0283,  0.0388, -0.0864,  0.1838, -0.6500, -0.1512,  0.2088],\n",
      "        [ 0.0561,  0.0061,  0.0934, -0.1666,  0.1272, -0.5512, -0.3549,  0.0698],\n",
      "        [-0.0255,  0.0720, -0.7790, -0.0651,  0.1271, -0.1607, -0.1948,  0.0879],\n",
      "        [-0.3870,  0.0909,  0.0525, -0.0342,  0.0777, -0.5152, -0.1509,  0.0721],\n",
      "        [-0.1256,  0.1418,  0.0562, -0.1245, -0.0947, -0.1670, -0.3574,  0.1665],\n",
      "        [ 0.1702,  0.2194, -0.7297, -0.1137, -0.2793,  0.2847, -0.5775,  0.2026]],\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "layer = 0\n",
    "block = dict(dict(dict(model.named_children())['blocks'].named_children())[str(layer)].named_children())\n",
    "# list(block['attn'].children())[0]\n",
    "ls = [list(block['attn'].children())[0], list(block['attn'].children())[4],list(block['mlp'].children())[0], list(block['mlp'].children())[4]]\n",
    "ls[0]\n",
    "block['attn']\n",
    "print((block['attn'](dummy_input))[1,:8,:8])\n",
    "# torch.round(dict(dict(model.named_children())['blocks'].named_children())[str(0)](dummy_input)[0,:8,:8]*100)/100\n",
    "# dict(dict(model.named_children())['blocks'].named_children())[str(0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attention(\n",
       "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "  (q_norm): Identity()\n",
       "  (k_norm): Identity()\n",
       "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block['attn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kkh38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
