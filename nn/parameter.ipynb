{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "torch.manual_seed(20)\n",
    "ls = list()\n",
    "ls.append(nn.Linear(784, 50))\n",
    "ls.append(nn.Linear(50, 30))\n",
    "ls.append(nn.Linear(30, 40))\n",
    "ls.append(nn.Linear(40, 10))\n",
    "\n",
    "ls_W = list()\n",
    "for i in ls:\n",
    "    ls_W.append(i.weight.detach().T)\n",
    "    ls_W.append(i.bias)\n",
    "# .tofile('./weight/blocks.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([784, 50])\n",
      "torch.Size([50])\n",
      "torch.Size([50, 30])\n",
      "torch.Size([30])\n",
      "torch.Size([30, 40])\n",
      "torch.Size([40])\n",
      "torch.Size([40, 10])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for i in ls_W:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1381, -0.0392, -0.1167,  0.0576, -0.0649,  0.0762, -0.0374, -0.0546],\n",
       "        [-0.0223, -0.0873,  0.0544,  0.0754, -0.1553,  0.0185, -0.1150,  0.1129],\n",
       "        [-0.0857,  0.1376, -0.0815, -0.0897,  0.0014, -0.0192,  0.1514, -0.1348],\n",
       "        [-0.1487,  0.0774, -0.1488, -0.0509,  0.1436, -0.1402, -0.1425,  0.0908],\n",
       "        [ 0.1373,  0.0775,  0.1055,  0.0791, -0.0604, -0.1312,  0.0034,  0.0533],\n",
       "        [-0.1258,  0.1252,  0.1527, -0.0910, -0.0345, -0.1377,  0.0695,  0.0361],\n",
       "        [-0.0373, -0.0577, -0.1283, -0.1017,  0.0515,  0.0751, -0.0216,  0.0044],\n",
       "        [-0.1199, -0.0121, -0.1258, -0.1540, -0.1112, -0.1345, -0.1343,  0.0014]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_W[6][:8,:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([784, 50])\n",
      "torch.Size([50])\n",
      "torch.Size([50, 30])\n",
      "torch.Size([30])\n",
      "torch.Size([30, 40])\n",
      "torch.Size([40])\n",
      "torch.Size([40, 10])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for i in ls_W:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ls_W)):\n",
    "    ls_W[i].detach().numpy().tofile('./weight/'+str(i)+'_init_blocks'+'.bin')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "dd = torchvision.datasets.MNIST('./data',train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data = nn.LayerNorm((784),elementwise_affine=False)(dd.data.detach().reshape(-1, 28*28).to(float))\n",
    "mnist_data = mnist_data.numpy().astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.44079015 -0.44079015 -0.44079015 -0.44079015 -0.44079015 -0.44079015\n",
      "  -0.44079015 -0.44079015]\n",
      " [ 1.4226017   2.5431545   1.4226017   0.1232371  -0.4728017  -0.4728017\n",
      "  -0.4728017  -0.4728017 ]\n",
      " [-0.37816164 -0.37816164 -0.37816164 -0.37816164 -0.37816164 -0.37816164\n",
      "  -0.37816164 -0.37816164]\n",
      " [-0.33075416 -0.33075416 -0.33075416 -0.33075416 -0.33075416 -0.33075416\n",
      "  -0.33075416 -0.33075416]]\n"
     ]
    }
   ],
   "source": [
    "i =128\n",
    "print(mnist_data[:4,i:i+8])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist_data.tofile('./data/data_norm.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist_label = dd.targets.detach().numpy().astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist_label.tofile('./data/label.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 784)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_data[:4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ls  = list()\n",
    "for i in ls[:-1]:\n",
    "    n_ls.append(i)\n",
    "    n_ls.append(nn.ReLU())\n",
    "\n",
    "n_ls.append(ls[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=50, out_features=30, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=30, out_features=40, bias=True)\n",
       "  (5): ReLU()\n",
       "  (6): Linear(in_features=40, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(*n_ls)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = list()\n",
    "Z = list()\n",
    "Z.append(n_ls[0](torch.Tensor(mnist_data[:16])))\n",
    "A.append(n_ls[1](Z[0]))\n",
    "Z.append(n_ls[2](A[0]))\n",
    "A.append(n_ls[3](Z[1]))\n",
    "Z.append(n_ls[4](A[1]))\n",
    "A.append(n_ls[5](Z[2]))\n",
    "Z.append(n_ls[6](A[2]))\n",
    "A.append(Z[3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2984, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0996, 0.1178, 0.0848, 0.1139, 0.1134, 0.0906, 0.0825, 0.1123],\n",
       "        [0.1026, 0.1183, 0.0866, 0.1059, 0.1101, 0.0924, 0.0840, 0.1094],\n",
       "        [0.0992, 0.1183, 0.0839, 0.1074, 0.1113, 0.0942, 0.0831, 0.1115],\n",
       "        [0.0982, 0.1225, 0.0827, 0.1064, 0.1092, 0.0942, 0.0855, 0.1123],\n",
       "        [0.1010, 0.1161, 0.0826, 0.1120, 0.1152, 0.0918, 0.0840, 0.1107],\n",
       "        [0.0999, 0.1187, 0.0838, 0.1092, 0.1141, 0.0921, 0.0840, 0.1117],\n",
       "        [0.1005, 0.1166, 0.0858, 0.1103, 0.1142, 0.0897, 0.0860, 0.1099],\n",
       "        [0.1032, 0.1180, 0.0847, 0.1064, 0.1109, 0.0923, 0.0838, 0.1114]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_label = dd.targets\n",
    "O = nn.Softmax(dim=1)(A[3])\n",
    "print(nn.CrossEntropyLoss()(O, mnist_label[:16]))\n",
    "O[8:,:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2013, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0569, 0.0000],\n",
       "        [0.1143, 0.0000, 0.4939, 0.0000, 0.0000, 0.3471, 0.0944, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.6248, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1605, 0.6952, 0.0000, 0.0340, 0.5496, 0.0000, 0.0144, 0.1711],\n",
       "        [0.2259, 0.1223, 0.0000, 0.0000, 0.0000, 0.0088, 0.1536, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.1839, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5416, 0.0383, 0.0278, 0.0000, 0.0000, 0.3027, 0.0000, 0.0000],\n",
       "        [0.0062, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4925, 0.0000]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "A_0 = n_ls[0](torch.Tensor(mnist_data[:8]))\n",
    "A_0 = n_ls[1](A_0)\n",
    "A_0[:,:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0953, 0.1488, 0.0276, 0.1052, 0.1098, 0.0852, 0.1387, 0.1294],\n",
       "        [0.1247, 0.2620, 0.1786, 0.1021, 0.2590, 0.2786, 0.1823, 0.1476],\n",
       "        [0.0766, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1419, 0.1329, 0.1130, 0.0596, 0.0484, 0.0798, 0.1312, 0.1729],\n",
       "        [0.0661, 0.0912, 0.0395, 0.0000, 0.0095, 0.0150, 0.0297, 0.0627],\n",
       "        [0.4032, 0.4439, 0.2506, 0.3235, 0.2949, 0.3188, 0.2001, 0.3688],\n",
       "        [0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0347, 0.0930, 0.0000, 0.0000, 0.0000, 0.0000, 0.0778, 0.0000]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[2].T[8:16,:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0988,  0.1182,  0.0870,  0.1112,  0.1146, -0.9105,  0.0815,  0.1116],\n",
       "        [-0.8975,  0.1154,  0.0875,  0.1068,  0.1155,  0.0884,  0.0799,  0.1111],\n",
       "        [ 0.1007,  0.1203,  0.0821,  0.1075, -0.8902,  0.0957,  0.0845,  0.1102],\n",
       "        [ 0.1020, -0.8835,  0.0879,  0.1098,  0.1102,  0.0901,  0.0855,  0.1086],\n",
       "        [ 0.1026,  0.1175,  0.0857,  0.1102,  0.1142,  0.0913,  0.0812,  0.1105],\n",
       "        [ 0.1029,  0.1177, -0.9156,  0.1082,  0.1126,  0.0932,  0.0818,  0.1111],\n",
       "        [ 0.1007, -0.8849,  0.0865,  0.1102,  0.1134,  0.0922,  0.0832,  0.1107],\n",
       "        [ 0.1003,  0.1211,  0.0831, -0.8951,  0.1084,  0.0955,  0.0846,  0.1112],\n",
       "        [ 0.0996, -0.8822,  0.0848,  0.1139,  0.1134,  0.0906,  0.0825,  0.1123],\n",
       "        [ 0.1026,  0.1183,  0.0866,  0.1059, -0.8899,  0.0924,  0.0840,  0.1094],\n",
       "        [ 0.0992,  0.1183,  0.0839, -0.8926,  0.1113,  0.0942,  0.0831,  0.1115],\n",
       "        [ 0.0982,  0.1225,  0.0827,  0.1064,  0.1092, -0.9058,  0.0855,  0.1123],\n",
       "        [ 0.1010,  0.1161,  0.0826, -0.8880,  0.1152,  0.0918,  0.0840,  0.1107],\n",
       "        [ 0.0999,  0.1187,  0.0838,  0.1092,  0.1141,  0.0921, -0.9160,  0.1117],\n",
       "        [ 0.1005, -0.8834,  0.0858,  0.1103,  0.1142,  0.0897,  0.0860,  0.1099],\n",
       "        [ 0.1032,  0.1180,  0.0847,  0.1064,  0.1109,  0.0923,  0.0838, -0.8886]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dCE[:,:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3267,  2.1735, -3.0872,  0.8687,  1.3822, -1.7991, -3.3708,  1.1807,\n",
       "        -1.3833, -1.4389], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = torch.eye(10)[mnist_label[:16]]\n",
    "\n",
    "dCE = O-Y\n",
    "\n",
    "torch.round(torch.matmul(A[2].T, dCE)[8:16,:8]*1000) /1000\n",
    "torch.sum(A[3], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0996, 0.1178, 0.0848, 0.1139, 0.1134, 0.0906, 0.0825, 0.1123],\n",
       "        [0.1026, 0.1183, 0.0866, 0.1059, 0.1101, 0.0924, 0.0840, 0.1094],\n",
       "        [0.0992, 0.1183, 0.0839, 0.1074, 0.1113, 0.0942, 0.0831, 0.1115],\n",
       "        [0.0982, 0.1225, 0.0827, 0.1064, 0.1092, 0.0942, 0.0855, 0.1123],\n",
       "        [0.1010, 0.1161, 0.0826, 0.1120, 0.1152, 0.0918, 0.0840, 0.1107],\n",
       "        [0.0999, 0.1187, 0.0838, 0.1092, 0.1141, 0.0921, 0.0840, 0.1117],\n",
       "        [0.1005, 0.1166, 0.0858, 0.1103, 0.1142, 0.0897, 0.0860, 0.1099],\n",
       "        [0.1032, 0.1180, 0.0847, 0.1064, 0.1109, 0.0923, 0.0838, 0.1114]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O[8:,:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4855e-02, -2.8435e-01,  5.2957e-02, -2.4561e-01,  1.0235e-01,\n",
       "         -5.3971e-02,  6.5279e-02,  1.5166e-01],\n",
       "        [ 1.7984e-02, -2.8859e-01, -4.3565e-02, -1.9924e-01, -1.2070e-02,\n",
       "          8.4585e-02,  4.2112e-02,  1.3610e-01],\n",
       "        [ 9.2253e-03, -5.5034e-03,  8.0826e-03,  1.0337e-02,  1.0661e-02,\n",
       "         -6.8279e-02,  7.6636e-03,  1.0362e-02],\n",
       "        [ 3.8976e-02, -9.8948e-02,  6.4955e-02, -2.9380e-01, -2.2951e-02,\n",
       "         -1.0003e-01,  4.9247e-02,  8.8140e-02],\n",
       "        [-3.7952e-02,  1.3469e-03,  2.9989e-02, -6.6452e-02, -5.1667e-02,\n",
       "         -1.7575e-02,  4.3578e-02,  8.2393e-03],\n",
       "        [ 6.7266e-02, -3.2462e-01,  1.1157e-01, -4.1161e-01, -6.3146e-02,\n",
       "         -2.1183e-01,  5.3375e-02,  1.1777e-01],\n",
       "        [ 3.8623e-04,  4.6194e-04,  3.4023e-04,  4.3471e-04,  4.4796e-04,\n",
       "         -3.5592e-03,  3.1873e-04,  4.3632e-04],\n",
       "        [-4.9335e-02, -1.2435e-01,  3.7023e-02, -8.3024e-02,  4.9478e-02,\n",
       "          4.5453e-03,  3.5935e-02,  4.8013e-02]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(A[2].T,dCE)[8:16,:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0280,  0.0830, -0.1580, -0.0900, -0.0400, -0.1320,  0.0400, -0.0840],\n",
       "        [ 0.0540,  0.1510, -0.0200, -0.1580,  0.0980,  0.0290, -0.0680,  0.0150],\n",
       "        [-0.0690, -0.0800,  0.0710,  0.0380, -0.0430,  0.0850,  0.0850,  0.0580],\n",
       "        [-0.0880, -0.0230,  0.0010,  0.1270,  0.1680,  0.1320, -0.0920,  0.0390],\n",
       "        [-0.0680, -0.0810,  0.0700,  0.0380, -0.0420,  0.0830,  0.0850,  0.0580],\n",
       "        [ 0.0260,  0.1100, -0.1700,  0.1300,  0.0330, -0.0750,  0.0050,  0.0390],\n",
       "        [ 0.0280,  0.0820, -0.1560, -0.0910, -0.0400, -0.1310,  0.0410, -0.0840],\n",
       "        [ 0.0440, -0.1170,  0.1160, -0.1050, -0.0160, -0.0420, -0.0210, -0.0970]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.round(torch.matmul(dCE, n_ls[3*2].weight)*1000)/1000)[8:,:8]\n",
    "# (n_ls[3*2].weight.T)[8:16,:8]\n",
    "#  A[3][8:,:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.2169, 0.0000, 0.0000, 0.0000, 0.0000, 0.0953,\n",
       "         0.1247, 0.0766, 0.1419, 0.0661, 0.4032, 0.0039, 0.0347, 0.2394, 0.0705,\n",
       "         0.0000, 0.1461, 0.0000, 0.0986, 0.0000, 0.0000, 0.0000, 0.0000, 0.0464,\n",
       "         0.1349, 0.0000, 0.0000, 0.2248, 0.1526, 0.0000, 0.0000, 0.3292, 0.1120,\n",
       "         0.0000, 0.0000, 0.0845, 0.0723],\n",
       "        [0.0000, 0.0000, 0.0000, 0.1868, 0.0000, 0.0000, 0.0000, 0.0000, 0.1488,\n",
       "         0.2620, 0.0000, 0.1329, 0.0912, 0.4439, 0.0000, 0.0930, 0.0983, 0.0000,\n",
       "         0.0158, 0.3169, 0.0845, 0.0402, 0.0000, 0.0000, 0.0000, 0.0000, 0.0538,\n",
       "         0.2010, 0.0000, 0.0758, 0.2067, 0.0000, 0.0000, 0.0000, 0.3267, 0.0000,\n",
       "         0.0000, 0.0000, 0.1636, 0.0000],\n",
       "        [0.1823, 0.0000, 0.0000, 0.0882, 0.0273, 0.0000, 0.0000, 0.0000, 0.0276,\n",
       "         0.1786, 0.0000, 0.1130, 0.0395, 0.2506, 0.0000, 0.0000, 0.0719, 0.0000,\n",
       "         0.0932, 0.0816, 0.0000, 0.1422, 0.1062, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.1407, 0.0000, 0.0000, 0.1792, 0.0625, 0.0000, 0.0000, 0.0395, 0.0000,\n",
       "         0.0000, 0.0000, 0.0834, 0.0886],\n",
       "        [0.0302, 0.0000, 0.0000, 0.0495, 0.0000, 0.0760, 0.0000, 0.0000, 0.1052,\n",
       "         0.1021, 0.0000, 0.0596, 0.0000, 0.3235, 0.0000, 0.0000, 0.1713, 0.0091,\n",
       "         0.0000, 0.2226, 0.0000, 0.1380, 0.0645, 0.0000, 0.0097, 0.0000, 0.1853,\n",
       "         0.1302, 0.0000, 0.0000, 0.2010, 0.0000, 0.0000, 0.0000, 0.2530, 0.1061,\n",
       "         0.0000, 0.0000, 0.1833, 0.0138],\n",
       "        [0.0808, 0.0000, 0.0000, 0.1398, 0.0000, 0.0000, 0.0000, 0.0000, 0.1098,\n",
       "         0.2590, 0.0000, 0.0484, 0.0095, 0.2949, 0.0000, 0.0000, 0.1611, 0.0000,\n",
       "         0.0000, 0.0854, 0.0040, 0.1151, 0.1294, 0.0000, 0.0000, 0.0030, 0.0593,\n",
       "         0.1078, 0.0000, 0.0000, 0.1991, 0.0000, 0.0000, 0.0000, 0.2236, 0.0419,\n",
       "         0.0000, 0.0000, 0.0224, 0.0705],\n",
       "        [0.1489, 0.0000, 0.0000, 0.0755, 0.0000, 0.0000, 0.0000, 0.0000, 0.0852,\n",
       "         0.2786, 0.0000, 0.0798, 0.0150, 0.3188, 0.0000, 0.0000, 0.1278, 0.0000,\n",
       "         0.0000, 0.0468, 0.0000, 0.1848, 0.0946, 0.0000, 0.0000, 0.0502, 0.0199,\n",
       "         0.1310, 0.0000, 0.0000, 0.1574, 0.0516, 0.0000, 0.0000, 0.0854, 0.0000,\n",
       "         0.0000, 0.0000, 0.0705, 0.0905],\n",
       "        [0.1415, 0.0000, 0.0000, 0.1225, 0.0192, 0.0000, 0.0000, 0.0000, 0.1387,\n",
       "         0.1823, 0.0000, 0.1312, 0.0297, 0.2001, 0.0000, 0.0778, 0.1302, 0.0000,\n",
       "         0.0000, 0.1107, 0.0625, 0.1730, 0.0893, 0.0000, 0.0000, 0.0000, 0.0390,\n",
       "         0.0854, 0.0000, 0.0000, 0.1954, 0.0022, 0.0000, 0.0000, 0.1745, 0.0193,\n",
       "         0.0000, 0.0000, 0.0709, 0.1145],\n",
       "        [0.0908, 0.0000, 0.0000, 0.0751, 0.0000, 0.0368, 0.0000, 0.0000, 0.1294,\n",
       "         0.1476, 0.0000, 0.1729, 0.0627, 0.3688, 0.0000, 0.0000, 0.0541, 0.0000,\n",
       "         0.0866, 0.1791, 0.0520, 0.0649, 0.1181, 0.0000, 0.0000, 0.0000, 0.0192,\n",
       "         0.1533, 0.0000, 0.0000, 0.1673, 0.0000, 0.0000, 0.0000, 0.1154, 0.0000,\n",
       "         0.0000, 0.0000, 0.1604, 0.0622],\n",
       "        [0.1223, 0.0000, 0.0000, 0.1645, 0.0464, 0.0000, 0.0000, 0.0000, 0.1180,\n",
       "         0.2255, 0.0000, 0.0181, 0.0312, 0.2308, 0.0000, 0.0210, 0.1964, 0.0000,\n",
       "         0.0000, 0.0497, 0.0000, 0.2391, 0.1260, 0.0000, 0.0000, 0.0420, 0.0688,\n",
       "         0.0902, 0.0000, 0.0000, 0.2582, 0.0722, 0.0000, 0.0000, 0.1173, 0.0708,\n",
       "         0.0000, 0.0000, 0.0413, 0.1693],\n",
       "        [0.0856, 0.0000, 0.0000, 0.0434, 0.0000, 0.0461, 0.0000, 0.0000, 0.0529,\n",
       "         0.1451, 0.0000, 0.1012, 0.0712, 0.3803, 0.0000, 0.0000, 0.1373, 0.0000,\n",
       "         0.0237, 0.1277, 0.0000, 0.1028, 0.0380, 0.0000, 0.0072, 0.0000, 0.1196,\n",
       "         0.2152, 0.0000, 0.0000, 0.1381, 0.0221, 0.0000, 0.0000, 0.1489, 0.0000,\n",
       "         0.0000, 0.0000, 0.1860, 0.0424],\n",
       "        [0.0610, 0.0000, 0.0000, 0.1713, 0.0000, 0.0000, 0.0000, 0.0000, 0.1718,\n",
       "         0.1821, 0.0000, 0.2098, 0.0606, 0.3787, 0.0000, 0.0405, 0.0877, 0.0000,\n",
       "         0.0710, 0.2383, 0.0949, 0.1069, 0.0318, 0.0000, 0.0000, 0.0000, 0.0062,\n",
       "         0.1334, 0.0000, 0.0000, 0.2219, 0.0000, 0.0000, 0.0000, 0.2147, 0.0000,\n",
       "         0.0000, 0.0000, 0.1373, 0.0000],\n",
       "        [0.0625, 0.0000, 0.0000, 0.1492, 0.0000, 0.0338, 0.0000, 0.0000, 0.1079,\n",
       "         0.0451, 0.0000, 0.1158, 0.0000, 0.2743, 0.0000, 0.0000, 0.0723, 0.0817,\n",
       "         0.0458, 0.1813, 0.0218, 0.0465, 0.1499, 0.0000, 0.0024, 0.0000, 0.0602,\n",
       "         0.1142, 0.0000, 0.0000, 0.2472, 0.0000, 0.0000, 0.0000, 0.1895, 0.0530,\n",
       "         0.0000, 0.0000, 0.1268, 0.0950],\n",
       "        [0.2229, 0.0000, 0.0000, 0.1802, 0.0351, 0.0189, 0.0000, 0.0000, 0.1214,\n",
       "         0.1707, 0.0000, 0.0957, 0.0000, 0.2126, 0.0000, 0.0901, 0.2514, 0.0000,\n",
       "         0.0000, 0.0244, 0.0000, 0.2403, 0.1054, 0.0000, 0.0000, 0.0000, 0.0383,\n",
       "         0.0738, 0.0000, 0.0000, 0.1430, 0.0307, 0.0000, 0.0000, 0.0000, 0.1203,\n",
       "         0.0000, 0.0000, 0.1785, 0.0838],\n",
       "        [0.0796, 0.0000, 0.0000, 0.1584, 0.0074, 0.0000, 0.0000, 0.0000, 0.0700,\n",
       "         0.1875, 0.0000, 0.0932, 0.0000, 0.3679, 0.0000, 0.0000, 0.1375, 0.0000,\n",
       "         0.0005, 0.2291, 0.0766, 0.1192, 0.0008, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.1147, 0.0000, 0.0000, 0.2535, 0.1168, 0.0000, 0.0000, 0.1453, 0.0570,\n",
       "         0.0000, 0.0000, 0.0933, 0.0265],\n",
       "        [0.0525, 0.0000, 0.0000, 0.1645, 0.0529, 0.0000, 0.0000, 0.0000, 0.1138,\n",
       "         0.1044, 0.0165, 0.0917, 0.0000, 0.1676, 0.0000, 0.0759, 0.1460, 0.0347,\n",
       "         0.0000, 0.1549, 0.0000, 0.2067, 0.0969, 0.0000, 0.0000, 0.0062, 0.1629,\n",
       "         0.0305, 0.0000, 0.0000, 0.2114, 0.0640, 0.0000, 0.0000, 0.1099, 0.1239,\n",
       "         0.0000, 0.0000, 0.0454, 0.1162],\n",
       "        [0.0756, 0.0107, 0.0000, 0.0956, 0.0000, 0.0000, 0.0000, 0.0000, 0.0286,\n",
       "         0.1708, 0.0000, 0.1012, 0.0502, 0.4435, 0.0000, 0.0000, 0.1355, 0.0000,\n",
       "         0.0000, 0.1963, 0.0000, 0.0902, 0.0000, 0.0000, 0.0000, 0.0000, 0.1128,\n",
       "         0.2194, 0.0000, 0.0000, 0.2104, 0.0056, 0.0000, 0.0000, 0.1952, 0.0145,\n",
       "         0.0000, 0.0000, 0.1834, 0.0000]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def dReLU(X):\n",
    "#     z = torch.zeros_like(X)\n",
    "#     return X if (X >=0) else z\n",
    "# dReLU(Z[2])\n",
    "((Z[2]>=0) *A[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kkh38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
